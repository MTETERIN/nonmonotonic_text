{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Translation (Transformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import tree_text_gen.binary.translation.evaluate as evaluate\n",
    "\n",
    "import os\n",
    "from glob import glob\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP\n",
    "\n",
    "First extract the models downloaded from [here](https://drive.google.com/file/d/172Ir1oNvHBgnLO1hWqDeiAcBH5i6pfwi/view?usp=sharing) into the `tree_text_gen` base directory. The cell below will then load the correct experiment directories. The cell prints the directories and the contents of an example experiment directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sw1986/projects/phd/tree_text_gen/models/translation/leftright',\n",
      " '/home/sw1986/projects/phd/tree_text_gen/models/translation/annealed_tree',\n",
      " '/home/sw1986/projects/phd/tree_text_gen/models/translation/uniform',\n",
      " '/home/sw1986/projects/phd/tree_text_gen/models/translation/annealed']\n",
      "leftright  leftright.checkpoint  model_config.json  tok2i.json\n"
     ]
    }
   ],
   "source": [
    "import tree_text_gen\n",
    "project_dir = os.path.abspath(os.path.join(os.path.dirname(tree_text_gen.__file__), os.pardir))\n",
    "dirs = glob(os.path.join(project_dir, 'models/translation/*'))\n",
    "pp(dirs)\n",
    "d = dirs[0]\n",
    "!ls $d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each model from `dirs`\n",
    "\n",
    "`exprs` will map experiment/model name to pytorch model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftright\n",
      "annealed_tree\n",
      "uniform\n",
      "annealed\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = False\n",
    "\n",
    "exprs = {}\n",
    "models = {}\n",
    "for d in dirs:\n",
    "    expr_name = d.split('/')[-1]\n",
    "    print(expr_name)\n",
    "    models[expr_name] = evaluate.load_transformer_eval(d, expr_name, checkpoint=CHECKPOINT)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from tree_text_gen.binary.translation.args import common_args\n",
    "from tree_text_gen.binary.translation.data import load_iwslt, load_iwslt_vocab\n",
    "from tree_text_gen.binary.common.util import setup\n",
    "import copy\n",
    "import torchtext.data\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "common_args(parser)\n",
    "args = parser.parse_args(args=[])\n",
    "args = setup(args, log=False)\n",
    "args.translate = \"{}_{}\".format(args.src, args.trg)\n",
    "args.logger = None\n",
    "\n",
    "# -- DATA\n",
    "train_data, dev_data, test_data, SRC, TRG = load_iwslt(args)\n",
    "tok2i, i2tok, SRC, TRG = load_iwslt_vocab(args, SRC, TRG, args.data_prefix)\n",
    "\n",
    "SRC = copy.deepcopy(SRC)\n",
    "for data_ in [train_data, dev_data, test_data]:\n",
    "    if not data_ is None:\n",
    "        data_.fields['src'] = SRC\n",
    "        \n",
    "sort_key = lambda x: len(x.src)\n",
    "trainloader = torchtext.data.BucketIterator(dataset=train_data, batch_size=args.batch_size, device=args.device, train=True, repeat=False, shuffle=True, sort_key=sort_key, sort_within_batch=True)\n",
    "validloader = torchtext.data.BucketIterator(dataset=dev_data, batch_size=args.batch_size, device=args.device, train=False, repeat=False, shuffle=True, sort_key=sort_key, sort_within_batch=True)\n",
    "testloader = torchtext.data.BucketIterator(dataset=test_data, batch_size=args.batch_size, device=args.device, train=False, repeat=False, shuffle=False, sort_key=sort_key, sort_within_batch=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For the `+ tree-encoding` result (i.e. tree encoding without end tuning), set `end_tuned = False` below.\n",
    "\n",
    "\n",
    "#### Meteor and Yisi Note\n",
    "Meteor and Yisi require additional setup; **comment out** `common_eval.eval_meteor()` **and** `common_eval.eval_yisi()` **below unless you have them set up**. \n",
    "\n",
    "You will probably need to look at the `common_eval.eval_meteor()` and `common_eval.eval_yisi()` code and arguments to get it running on your environment.\n",
    "- [meteor setup](https://www.cs.cmu.edu/~alavie/METEOR/README.html)\n",
    "- [yisi setup](https://github.com/chikiulo/yisi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tree_text_gen.binary.translation.evaluate as evaluate\n",
    "import tree_text_gen.binary.common.evaluate as common_eval\n",
    "import tree_text_gen.binary.common.samplers as samplers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== leftright ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:40<00:00,  1.23s/it]\n",
      "# RIBES evaluation start at 2019-04-30 16:37:33.497879\n",
      "# RIBES evaluation done at 2019-04-30 16:37:33.708625\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU+case.mixed+numrefs.1+smooth.none+tok.13a+version.1.2.12 = 32.3 65.7/41.1/28.1/19.7 (BP = 0.923 ratio = 0.926 hyp_len = 20841 ref_len = 22509)\n",
      "\n",
      "{'bleu': 32.3,\n",
      " 'meteor': 0.3195953154322145,\n",
      " 'ribes': 0.848027,\n",
      " 'yisi': 0.694072}\n",
      "=== annealed_tree_end_tuned ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:53<00:00,  1.53s/it]\n",
      "# RIBES evaluation start at 2019-04-30 16:39:06.556216\n",
      "# RIBES evaluation done at 2019-04-30 16:39:06.748772\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU+case.mixed+numrefs.1+smooth.none+tok.13a+version.1.2.12 = 29.1 61.4/35.9/22.9/15.1 (BP = 0.986 ratio = 0.986 hyp_len = 22193 ref_len = 22509)\n",
      "\n",
      "{'bleu': 29.1,\n",
      " 'meteor': 0.30999861976223303,\n",
      " 'ribes': 0.835089,\n",
      " 'yisi': 0.688148}\n",
      "=== uniform ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:41<00:00,  1.29s/it]\n",
      "# RIBES evaluation start at 2019-04-30 16:40:26.363024\n",
      "# RIBES evaluation done at 2019-04-30 16:40:26.589651\n",
      "  0%|          | 0/32 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU+case.mixed+numrefs.1+smooth.none+tok.13a+version.1.2.12 = 24.5 64.3/36.3/22.2/14.1 (BP = 0.838 ratio = 0.849 hyp_len = 19119 ref_len = 22509)\n",
      "\n",
      "{'bleu': 24.5,\n",
      " 'meteor': 0.27981935032263144,\n",
      " 'ribes': 0.826607,\n",
      " 'yisi': 0.663999}\n",
      "=== annealed ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32/32 [00:43<00:00,  1.34s/it]\n",
      "# RIBES evaluation start at 2019-04-30 16:41:48.825809\n",
      "# RIBES evaluation done at 2019-04-30 16:41:49.003298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BLEU+case.mixed+numrefs.1+smooth.none+tok.13a+version.1.2.12 = 26.8 64.6/37.1/23.2/15.3 (BP = 0.882 ratio = 0.889 hyp_len = 20007 ref_len = 22509)\n",
      "\n",
      "{'bleu': 26.8,\n",
      " 'meteor': 0.2967353647960145,\n",
      " 'ribes': 0.836156,\n",
      " 'yisi': 0.678767}\n"
     ]
    }
   ],
   "source": [
    "dataloader = validloader\n",
    "# dataloader = testloader\n",
    "\n",
    "end_tuned = True\n",
    "\n",
    "for name, model in models.items():\n",
    "    if end_tuned and 'tree' in name:\n",
    "        model.module.stop_prob = 0.67\n",
    "        name += '_end_tuned'\n",
    "        \n",
    "    print('=== %s ===' % (name))\n",
    "    ms, predictions = evaluate.eval_dataset(model, dataloader)\n",
    "    out = {}\n",
    "    out['meteor'] = common_eval.eval_meteor()\n",
    "    out['ribes'] = common_eval.eval_ribes()\n",
    "    out['yisi'] = common_eval.eval_yisi()\n",
    "    out['bleu'] = common_eval.eval_sacrebleu()\n",
    "    pp(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
