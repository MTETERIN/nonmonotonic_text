{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unconditional Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline\n",
    "import tree_text_gen.binary.unconditional.evaluate as evaluate\n",
    "from pprint import pprint as pp\n",
    "import os\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SETUP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First extract the models downloaded from [here](https://drive.google.com/file/d/1HmtxtzGG3tvQBk6tPtKn_OsMnA0LcjqX/view?usp=sharing) into the `tree_text_gen` base directory. The cell below will then load the correct experiment directories. The cell prints the directories and the contents of an example experiment directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/sw1986/projects/phd/tree_text_gen/models/unconditional/leftright',\n",
      " '/home/sw1986/projects/phd/tree_text_gen/models/unconditional/uniform',\n",
      " '/home/sw1986/projects/phd/tree_text_gen/models/unconditional/annealed']\n",
      "leftright.checkpoint  model_config.json  tok2i.json\n"
     ]
    }
   ],
   "source": [
    "import tree_text_gen\n",
    "project_dir = os.path.abspath(os.path.join(os.path.dirname(tree_text_gen.__file__), os.pardir))\n",
    "dirs = glob(os.path.join(project_dir, 'models/unconditional/*'))\n",
    "pp(dirs)\n",
    "d = dirs[0]\n",
    "!ls $d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load each model specified in `exprs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "leftright\n",
      "uniform\n",
      "annealed\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT = True\n",
    "\n",
    "exprs = {}\n",
    "for d in dirs:\n",
    "    expr_name = d.split('/')[-1]\n",
    "    exprs[expr_name] = d\n",
    "\n",
    "models = {}\n",
    "for k, v in exprs.items():\n",
    "    print(k)\n",
    "    models[k] = evaluate.load_model(v, k, checkpoint=CHECKPOINT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "\n",
    "Below shows samples from each model using the specified sampler.\n",
    "\n",
    "Select `show_trees` to print out corresponding trees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topk is the k for a topk-sampler (-1 for k = all)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74f87b8045cb48e086aa8102a21d139c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='topk', options=(-1, 3, 10, 100, 1000, 10000), value=-1), Checkbox(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets\n",
    "import torch.nn.functional as F\n",
    "import torch as th\n",
    "import seaborn as sns\n",
    "from tree_text_gen.binary.common.data import load_personachat, build_tok2i, SentenceDataset, inds2toks\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import tree_text_gen.binary.common.samplers as samplers\n",
    "\n",
    "def run(topk, show_trees, n=fixed(10)):\n",
    "    for name, model in models.items():\n",
    "        k = topk\n",
    "        if k == -1:\n",
    "            model.sampler.eval_sampler = samplers.StochasticSampler()\n",
    "        else:\n",
    "            model.sampler.eval_sampler = samplers.TopkSampler(k, model.device)\n",
    "        out = evaluate.sample(model, n)\n",
    "        \n",
    "        print('=== %s ===' % name)\n",
    "        for o in out:\n",
    "            if show_trees:\n",
    "                evaluate.print_output(o)\n",
    "            else:\n",
    "                print(' '.join(o['inorder_tokens']))\n",
    "        print('---------------------------------------------------')\n",
    "\n",
    "print(\"topk is the k for a topk-sampler (-1 for k = all)\")\n",
    "interact(run, topk=[-1, 3, 10, 100, 1000, 10000], show_trees=False);    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Completion\n",
    "\n",
    "Select root, left child, and right child words for a seed tree. Sampled tree completions are then shown for each model. Select `show_trees` to show each sample's corresponding tree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee2639023a5b41c58ecba4260975c9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='root', index=28, options=('<s>', '<p>', '</s>', '<unk>', '<end>', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "words = list(list(models.values())[0].tok2i.keys())\n",
    "\n",
    "def run(root='favorite', lchild='my', rchild='!', show_trees=False, topk=100, n=fixed(5)):\n",
    "    for name in ['uniform', 'annealed', 'leftright']:\n",
    "        model = models[name]\n",
    "        k = topk\n",
    "        if k == -1:\n",
    "            model.sampler.eval_sampler = samplers.StochasticSampler()\n",
    "        else:\n",
    "            model.sampler.eval_sampler = samplers.TopkSampler(k, model.device)\n",
    "        tree_prefix_tokens = [root, lchild, rchild]\n",
    "        out, scores, samples = evaluate.sample_with_prefix(model, tree_prefix_tokens, n=5)\n",
    "        print('=== %s ===' % name)\n",
    "        for o in out:\n",
    "            if show_trees:\n",
    "                evaluate.print_output(o)\n",
    "            else:\n",
    "                print(' '.join(o['inorder_tokens']))\n",
    "        print('---------------------------------------------------')\n",
    "\n",
    "interact(run, root=words, lchild=words, rchild=words, topk=[-1,10,50,100,1000], show_trees=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
